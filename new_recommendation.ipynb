{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords') # Uncomment to download for initial run\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50b950ea60d4ccfbd0bfe13e7beff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Enter Here', description='Video Title:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d58f2d6c944f5e96fcbc441eed1465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv(\"video_info.csv\")\n",
    "data = data.drop_duplicates(subset='Title', keep=\"first\")\n",
    "\n",
    "# Confirm no null and duplicate values\n",
    "assert (data.isnull().sum() == 0).all() == True, \"Please review input csv file. Null values detected.\"\n",
    "assert data.duplicated(subset='Title').sum() == 0, \"Remove duplicative values in the input csv file.\"\n",
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    \"Clean show titles.\"\n",
    "    text = str(text).title()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = [word for word in text if word != '']\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "data[\"Title\"] = data[\"Title\"].apply(clean)\n",
    "data[\"title_n_genre\"] = data[\"Title\"] + \" \" + data[\"Genre\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf = vectorizer.fit_transform(data[\"title_n_genre\"])\n",
    "\n",
    "# Tokenize the 'title_n_genre' column\n",
    "data['tokens'] = data['title_n_genre'].apply(lambda x: x.split())\n",
    "\n",
    "# Train the Word2Vec model\n",
    "\n",
    "w2v_model = Word2Vec(data['tokens'], min_count=1, vector_size=50)\n",
    "\n",
    "def search(title):\n",
    "    title = clean(title)\n",
    "    query_vec = vectorizer.transform([title])\n",
    "    similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "\n",
    "    # Find similar words to the input title using Word2Vec model\n",
    "    try:\n",
    "        similar_words = w2v_model.wv.most_similar(title, topn=5)\n",
    "        similar_titles = [word[0] for word in similar_words]\n",
    "        similar_titles.append(title)  # Include the original title\n",
    "    except KeyError:\n",
    "        similar_titles = [title]\n",
    "\n",
    "    # Calculate cosine similarity for each similar title\n",
    "    similar_scores = []\n",
    "    for similar_title in similar_titles:\n",
    "        query_vec = vectorizer.transform([similar_title])\n",
    "        similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "        similar_scores.append(similarity)\n",
    "\n",
    "    # Combine the scores and sort by similarity\n",
    "    combined_scores = np.sum(similar_scores, axis=0)\n",
    "    indices = np.argpartition(combined_scores, -10)[-10:]\n",
    "    results = data.iloc[indices].iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    return results[['Title', 'Genre', 'URL']]\n",
    "\n",
    "movie_input = widgets.Text(\n",
    "    value='Enter Here',\n",
    "    description='Video Title:',\n",
    "    disabled=False\n",
    ")\n",
    "movie_list = widgets.Output()\n",
    "\n",
    "def on_type(data):\n",
    "    with movie_list:\n",
    "        movie_list.clear_output()\n",
    "        title = data[\"new\"]\n",
    "        display(search(title))\n",
    "\n",
    "movie_input.observe(on_type, names='value')\n",
    "\n",
    "\n",
    "display(movie_input, movie_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1083fdcaa164a78ac29d34196ede6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Enter Here', description='Video Title:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f16a033e9449bfa309e4f39a7c0077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv(\"video_info.csv\")\n",
    "data = data.drop_duplicates(subset='Title', keep=\"first\")\n",
    "\n",
    "# Confirm no null and duplicate values\n",
    "assert (data.isnull().sum() == 0).all() == True, \"Please review input csv file. Null values detected.\"\n",
    "assert data.duplicated(subset='Title').sum() == 0, \"Remove duplicative values in the input csv file.\"\n",
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    \"Clean show titles.\"\n",
    "    text = str(text).title()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = [word for word in text if word != '']\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "data[\"Title\"] = data[\"Title\"].apply(clean)\n",
    "data[\"title_n_genre\"] = data[\"Title\"] + \" \" + data[\"Genre\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf = vectorizer.fit_transform(data[\"title_n_genre\"])\n",
    "\n",
    "# def search(title):\n",
    "#     title = clean(title)\n",
    "#     query_vec = vectorizer.transform([title])\n",
    "#     similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "#     indices = np.argpartition(similarity, -10)[-10:]\n",
    "#     results = data.iloc[indices].iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "#     return results[['Title', 'Genre', 'URL']]\n",
    "\n",
    "def search(title):\n",
    "    title = clean(title)\n",
    "    query_vec = vectorizer.transform([title])\n",
    "    similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "\n",
    "    # Find similar words to the input title using Word2Vec model\n",
    "    try:\n",
    "        similar_words = w2v_model.wv.most_similar(title, topn=5)\n",
    "        similar_titles = [word[0] for word in similar_words]\n",
    "        similar_titles.append(title)  # Include the original title\n",
    "    except KeyError:\n",
    "        # Find similar words to the input title by searching the vocabulary\n",
    "        similar_titles = [word for word in w2v_model.wv.index_to_key if title.lower() in word.lower()]\n",
    "        similar_titles = similar_titles[:5] + [title]  # Limit to 5 similar titles plus the original title\n",
    "\n",
    "    # Calculate cosine similarity for each similar title\n",
    "    similar_scores = []\n",
    "    for similar_title in similar_titles:\n",
    "        query_vec = vectorizer.transform([similar_title])\n",
    "        similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "        similar_scores.append(similarity)\n",
    "\n",
    "    # Combine the scores and sort by similarity\n",
    "    combined_scores = np.sum(similar_scores, axis=0)\n",
    "    indices = np.argpartition(combined_scores, -10)[-10:]\n",
    "    results = data.iloc[indices].iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    return results[['Title', 'Genre', 'URL']]\n",
    "\n",
    "# Rest of the code remains the same\n",
    "\n",
    "\n",
    "movie_input = widgets.Text(\n",
    "    value='Enter Here',\n",
    "    description='Video Title:',\n",
    "    disabled=False\n",
    ")\n",
    "movie_list = widgets.Output()\n",
    "\n",
    "def on_type(data):\n",
    "    with movie_list:\n",
    "        movie_list.clear_output()\n",
    "        title = data[\"new\"]\n",
    "        display(search(title))\n",
    "\n",
    "movie_input.observe(on_type, names='value')\n",
    "\n",
    "display(movie_input, movie_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
